13-08-23 04:06[root]INFO | Training on acrobot environment for 1500 episodes
13-08-23 04:06[root]INFO | Agent Type: dgt
13-08-23 04:06[root]INFO | Log Directory: acrobot_cpu/dgt/aaai_15n_32x32c_v2_rand/
13-08-23 04:06[root]INFO | Random Weight Initialization: True
13-08-23 04:06[root]INFO | Training Started: 2023-08-13 04:06:13
13-08-23 04:06[root]INFO | Using Acrobot Environment
13-08-23 04:06[root]INFO | Hyperparameters: {"n_steps": 2048, "batch_size": 128, "gamma": 0.99, "gae_lambda": 0.94, "clip_range": 0.22, "vf_coef": 0.54, "ent_coef": 0.012, "learning_rate": 0.001, "max_grad_norm": 0.5, "n_epochs": 20}
13-08-23 04:06[root]INFO | ===================> Training with seed 105 <=================
13-08-23 04:06[root]INFO | Agent: DGT
13-08-23 04:06[root]INFO | Action Net Arch: DGT(
  (_and_act_fn): Softmax(dim=-1)
  (_predicate_l): Sequential(
    (0): Linear(in_features=6, out_features=15, bias=True)
  )
  (_and_l): XLinear(
    (_l): Linear(in_features=15, out_features=16, bias=False)
  )
  (_or_l): XLinear(
    (_l): Linear(in_features=16, out_features=3, bias=False)
  )
)
13-08-23 04:06[root]INFO | Value Net Arch: Sequential(
  (0): Linear(in_features=6, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=32, bias=True)
  (3): ReLU()
  (4): Linear(in_features=32, out_features=1, bias=True)
)
13-08-23 04:06[root]INFO | Episode: 0, Avg Reward: -500.0, Best Eval: -500.0
13-08-23 04:08[root]INFO | Episode: 50, Avg Reward: -413.0, Best Eval: -215.8
13-08-23 04:09[root]INFO | Episode: 100, Avg Reward: -301.55, Best Eval: -215.8
13-08-23 04:10[root]INFO | Episode: 150, Avg Reward: -170.25, Best Eval: -104.23333333333333
13-08-23 04:11[root]INFO | Episode: 200, Avg Reward: -130.98, Best Eval: -81.53333333333333
13-08-23 04:11[root]INFO | Episode: 250, Avg Reward: -103.71, Best Eval: -81.53333333333333
13-08-23 04:12[root]INFO | Episode: 300, Avg Reward: -96.02, Best Eval: -81.53333333333333
13-08-23 04:12[root]INFO | Episode: 350, Avg Reward: -94.02, Best Eval: -79.4
13-08-23 04:12[root]INFO | Episode: 400, Avg Reward: -87.45, Best Eval: -79.0
13-08-23 04:13[root]INFO | Episode: 450, Avg Reward: -86.79, Best Eval: -79.0
13-08-23 04:13[root]INFO | Episode: 500, Avg Reward: -85.35, Best Eval: -79.0
13-08-23 04:14[root]INFO | Episode: 550, Avg Reward: -85.64, Best Eval: -79.0
13-08-23 04:14[root]INFO | Episode: 600, Avg Reward: -86.03, Best Eval: -79.0
13-08-23 04:14[root]INFO | Episode: 650, Avg Reward: -84.27, Best Eval: -79.0
13-08-23 04:15[root]INFO | Episode: 700, Avg Reward: -87.49, Best Eval: -79.0
13-08-23 04:15[root]INFO | Episode: 750, Avg Reward: -87.52, Best Eval: -79.0
13-08-23 04:16[root]INFO | Episode: 800, Avg Reward: -89.1, Best Eval: -79.0
13-08-23 04:16[root]INFO | Episode: 850, Avg Reward: -90.21, Best Eval: -79.0
13-08-23 04:17[root]INFO | Episode: 900, Avg Reward: -88.51, Best Eval: -78.56666666666666
13-08-23 04:17[root]INFO | Episode: 950, Avg Reward: -85.06, Best Eval: -78.56666666666666
13-08-23 04:17[root]INFO | Episode: 1000, Avg Reward: -83.14, Best Eval: -78.56666666666666
13-08-23 04:18[root]INFO | Episode: 1050, Avg Reward: -91.08, Best Eval: -78.56666666666666
13-08-23 04:18[root]INFO | Episode: 1100, Avg Reward: -93.51, Best Eval: -78.56666666666666
13-08-23 04:19[root]INFO | Episode: 1150, Avg Reward: -87.23, Best Eval: -78.56666666666666
13-08-23 04:19[root]INFO | Episode: 1200, Avg Reward: -92.71, Best Eval: -78.56666666666666
13-08-23 04:19[root]INFO | Episode: 1250, Avg Reward: -96.96, Best Eval: -78.56666666666666
13-08-23 04:20[root]INFO | Episode: 1300, Avg Reward: -90.25, Best Eval: -78.56666666666666
13-08-23 04:20[root]INFO | Episode: 1350, Avg Reward: -87.35, Best Eval: -78.56666666666666
13-08-23 04:21[root]INFO | Episode: 1400, Avg Reward: -85.8, Best Eval: -78.56666666666666
13-08-23 04:21[root]INFO | Episode: 1450, Avg Reward: -83.07, Best Eval: -78.56666666666666
13-08-23 04:21[root]INFO | Agent: DGT
13-08-23 04:21[root]INFO | Action Net Arch: DGT(
  (_and_act_fn): Softmax(dim=-1)
  (_predicate_l): Sequential(
    (0): Linear(in_features=6, out_features=15, bias=True)
  )
  (_and_l): XLinear(
    (_l): Linear(in_features=15, out_features=16, bias=False)
  )
  (_or_l): XLinear(
    (_l): Linear(in_features=16, out_features=3, bias=False)
  )
)
13-08-23 04:21[root]INFO | Value Net Arch: Sequential(
  (0): Linear(in_features=6, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=32, bias=True)
  (3): ReLU()
  (4): Linear(in_features=32, out_features=1, bias=True)
)
13-08-23 04:22[root]INFO | ==============> Test reward for seeds [500, 600]: -79.71 +/- 12.523813317037268 <==========
13-08-23 04:22[root]INFO | Execution time of seed 105: 0 hours, 15 minutes, 49 seconds
