13-08-23 04:06[root]INFO | Training on acrobot environment for 1500 episodes
13-08-23 04:06[root]INFO | Agent Type: dgt
13-08-23 04:06[root]INFO | Log Directory: acrobot_cpu/dgt/aaai_15n_32x32c_v2_rand/
13-08-23 04:06[root]INFO | Random Weight Initialization: True
13-08-23 04:06[root]INFO | Training Started: 2023-08-13 04:06:19
13-08-23 04:06[root]INFO | Using Acrobot Environment
13-08-23 04:06[root]INFO | Hyperparameters: {"n_steps": 2048, "batch_size": 128, "gamma": 0.99, "gae_lambda": 0.94, "clip_range": 0.22, "vf_coef": 0.54, "ent_coef": 0.012, "learning_rate": 0.001, "max_grad_norm": 0.5, "n_epochs": 20}
13-08-23 04:06[root]INFO | ===================> Training with seed 120 <=================
13-08-23 04:06[root]INFO | Agent: DGT
13-08-23 04:06[root]INFO | Action Net Arch: DGT(
  (_and_act_fn): Softmax(dim=-1)
  (_predicate_l): Sequential(
    (0): Linear(in_features=6, out_features=15, bias=True)
  )
  (_and_l): XLinear(
    (_l): Linear(in_features=15, out_features=16, bias=False)
  )
  (_or_l): XLinear(
    (_l): Linear(in_features=16, out_features=3, bias=False)
  )
)
13-08-23 04:06[root]INFO | Value Net Arch: Sequential(
  (0): Linear(in_features=6, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=32, bias=True)
  (3): ReLU()
  (4): Linear(in_features=32, out_features=1, bias=True)
)
13-08-23 04:06[root]INFO | Episode: 0, Avg Reward: -500.0, Best Eval: -500.0
13-08-23 04:08[root]INFO | Episode: 50, Avg Reward: -452.2156862745098, Best Eval: -202.03333333333333
13-08-23 04:09[root]INFO | Episode: 100, Avg Reward: -343.98, Best Eval: -78.26666666666667
13-08-23 04:09[root]INFO | Episode: 150, Avg Reward: -184.96, Best Eval: -78.26666666666667
13-08-23 04:10[root]INFO | Episode: 200, Avg Reward: -119.99, Best Eval: -78.26666666666667
13-08-23 04:10[root]INFO | Episode: 250, Avg Reward: -104.78, Best Eval: -78.26666666666667
13-08-23 04:11[root]INFO | Episode: 300, Avg Reward: -99.49, Best Eval: -78.26666666666667
13-08-23 04:11[root]INFO | Episode: 350, Avg Reward: -102.26, Best Eval: -78.26666666666667
13-08-23 04:11[root]INFO | Episode: 400, Avg Reward: -98.53, Best Eval: -78.26666666666667
13-08-23 04:12[root]INFO | Episode: 450, Avg Reward: -91.92, Best Eval: -78.26666666666667
13-08-23 04:12[root]INFO | Episode: 500, Avg Reward: -91.33, Best Eval: -78.26666666666667
13-08-23 04:13[root]INFO | Episode: 550, Avg Reward: -86.04, Best Eval: -78.26666666666667
13-08-23 04:13[root]INFO | Episode: 600, Avg Reward: -89.76, Best Eval: -78.26666666666667
13-08-23 04:14[root]INFO | Episode: 650, Avg Reward: -92.39, Best Eval: -78.26666666666667
13-08-23 04:14[root]INFO | Episode: 700, Avg Reward: -87.23, Best Eval: -78.26666666666667
13-08-23 04:14[root]INFO | Episode: 750, Avg Reward: -91.76, Best Eval: -78.26666666666667
13-08-23 04:15[root]INFO | Episode: 800, Avg Reward: -92.27, Best Eval: -78.26666666666667
13-08-23 04:15[root]INFO | Episode: 850, Avg Reward: -85.06, Best Eval: -78.26666666666667
13-08-23 04:16[root]INFO | Episode: 900, Avg Reward: -85.92, Best Eval: -78.26666666666667
13-08-23 04:16[root]INFO | Episode: 950, Avg Reward: -84.99, Best Eval: -78.26666666666667
13-08-23 04:16[root]INFO | Episode: 1000, Avg Reward: -84.16, Best Eval: -78.26666666666667
13-08-23 04:17[root]INFO | Episode: 1050, Avg Reward: -86.3, Best Eval: -78.26666666666667
13-08-23 04:17[root]INFO | Episode: 1100, Avg Reward: -85.13, Best Eval: -78.26666666666667
13-08-23 04:18[root]INFO | Episode: 1150, Avg Reward: -84.21, Best Eval: -76.0
13-08-23 04:18[root]INFO | Episode: 1200, Avg Reward: -86.81, Best Eval: -76.0
13-08-23 04:18[root]INFO | Episode: 1250, Avg Reward: -89.21, Best Eval: -76.0
13-08-23 04:19[root]INFO | Episode: 1300, Avg Reward: -88.5, Best Eval: -76.0
13-08-23 04:19[root]INFO | Episode: 1350, Avg Reward: -91.29, Best Eval: -76.0
13-08-23 04:20[root]INFO | Episode: 1400, Avg Reward: -100.53, Best Eval: -76.0
13-08-23 04:20[root]INFO | Episode: 1450, Avg Reward: -104.09, Best Eval: -76.0
13-08-23 04:21[root]INFO | Agent: DGT
13-08-23 04:21[root]INFO | Action Net Arch: DGT(
  (_and_act_fn): Softmax(dim=-1)
  (_predicate_l): Sequential(
    (0): Linear(in_features=6, out_features=15, bias=True)
  )
  (_and_l): XLinear(
    (_l): Linear(in_features=15, out_features=16, bias=False)
  )
  (_or_l): XLinear(
    (_l): Linear(in_features=16, out_features=3, bias=False)
  )
)
13-08-23 04:21[root]INFO | Value Net Arch: Sequential(
  (0): Linear(in_features=6, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=32, bias=True)
  (3): ReLU()
  (4): Linear(in_features=32, out_features=1, bias=True)
)
13-08-23 04:21[root]INFO | ==============> Test reward for seeds [500, 600]: -81.66 +/- 14.224781193396263 <==========
13-08-23 04:21[root]INFO | Execution time of seed 120: 0 hours, 14 minutes, 58 seconds
