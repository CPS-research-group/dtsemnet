13-08-23 04:06[root]INFO | Training on acrobot environment for 1500 episodes
13-08-23 04:06[root]INFO | Agent Type: dgt
13-08-23 04:06[root]INFO | Log Directory: acrobot_cpu/dgt/aaai_15n_32x32c_v2_rand/
13-08-23 04:06[root]INFO | Random Weight Initialization: True
13-08-23 04:06[root]INFO | Training Started: 2023-08-13 04:06:15
13-08-23 04:06[root]INFO | Using Acrobot Environment
13-08-23 04:06[root]INFO | Hyperparameters: {"n_steps": 2048, "batch_size": 128, "gamma": 0.99, "gae_lambda": 0.94, "clip_range": 0.22, "vf_coef": 0.54, "ent_coef": 0.012, "learning_rate": 0.001, "max_grad_norm": 0.5, "n_epochs": 20}
13-08-23 04:06[root]INFO | ===================> Training with seed 110 <=================
13-08-23 04:06[root]INFO | Agent: DGT
13-08-23 04:06[root]INFO | Action Net Arch: DGT(
  (_and_act_fn): Softmax(dim=-1)
  (_predicate_l): Sequential(
    (0): Linear(in_features=6, out_features=15, bias=True)
  )
  (_and_l): XLinear(
    (_l): Linear(in_features=15, out_features=16, bias=False)
  )
  (_or_l): XLinear(
    (_l): Linear(in_features=16, out_features=3, bias=False)
  )
)
13-08-23 04:06[root]INFO | Value Net Arch: Sequential(
  (0): Linear(in_features=6, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=32, bias=True)
  (3): ReLU()
  (4): Linear(in_features=32, out_features=1, bias=True)
)
13-08-23 04:06[root]INFO | Episode: 0, Avg Reward: -500.0, Best Eval: -500.0
13-08-23 04:08[root]INFO | Episode: 50, Avg Reward: -462.96078431372547, Best Eval: -225.5
13-08-23 04:09[root]INFO | Episode: 100, Avg Reward: -356.61, Best Eval: -87.7
13-08-23 04:09[root]INFO | Episode: 150, Avg Reward: -189.36, Best Eval: -83.1
13-08-23 04:10[root]INFO | Episode: 200, Avg Reward: -118.71, Best Eval: -83.1
13-08-23 04:10[root]INFO | Episode: 250, Avg Reward: -107.46, Best Eval: -83.1
13-08-23 04:11[root]INFO | Episode: 300, Avg Reward: -100.82, Best Eval: -83.1
13-08-23 04:11[root]INFO | Episode: 350, Avg Reward: -103.38, Best Eval: -81.4
13-08-23 04:12[root]INFO | Episode: 400, Avg Reward: -113.69, Best Eval: -81.4
13-08-23 04:12[root]INFO | Episode: 450, Avg Reward: -113.35, Best Eval: -81.4
13-08-23 04:13[root]INFO | Episode: 500, Avg Reward: -107.08, Best Eval: -81.4
13-08-23 04:13[root]INFO | Episode: 550, Avg Reward: -101.95, Best Eval: -81.4
13-08-23 04:14[root]INFO | Episode: 600, Avg Reward: -125.31, Best Eval: -81.4
13-08-23 04:15[root]INFO | Episode: 650, Avg Reward: -128.15, Best Eval: -77.7
13-08-23 04:15[root]INFO | Episode: 700, Avg Reward: -101.46, Best Eval: -77.7
13-08-23 04:16[root]INFO | Episode: 750, Avg Reward: -102.98, Best Eval: -77.7
13-08-23 04:16[root]INFO | Episode: 800, Avg Reward: -103.46, Best Eval: -77.7
13-08-23 04:17[root]INFO | Episode: 850, Avg Reward: -98.38, Best Eval: -77.7
13-08-23 04:17[root]INFO | Episode: 900, Avg Reward: -92.68, Best Eval: -77.7
13-08-23 04:18[root]INFO | Episode: 950, Avg Reward: -96.93, Best Eval: -77.7
13-08-23 04:18[root]INFO | Episode: 1000, Avg Reward: -102.99, Best Eval: -77.7
13-08-23 04:18[root]INFO | Episode: 1050, Avg Reward: -96.93, Best Eval: -77.7
13-08-23 04:19[root]INFO | Episode: 1100, Avg Reward: -93.08, Best Eval: -77.7
13-08-23 04:19[root]INFO | Episode: 1150, Avg Reward: -86.98, Best Eval: -77.7
13-08-23 04:20[root]INFO | Episode: 1200, Avg Reward: -86.09, Best Eval: -77.7
13-08-23 04:20[root]INFO | Episode: 1250, Avg Reward: -95.57, Best Eval: -77.7
13-08-23 04:21[root]INFO | Episode: 1300, Avg Reward: -94.16, Best Eval: -77.7
13-08-23 04:21[root]INFO | Episode: 1350, Avg Reward: -86.88, Best Eval: -77.7
13-08-23 04:21[root]INFO | Episode: 1400, Avg Reward: -87.87, Best Eval: -77.7
13-08-23 04:22[root]INFO | Episode: 1450, Avg Reward: -98.83, Best Eval: -77.7
13-08-23 04:22[root]INFO | Agent: DGT
13-08-23 04:22[root]INFO | Action Net Arch: DGT(
  (_and_act_fn): Softmax(dim=-1)
  (_predicate_l): Sequential(
    (0): Linear(in_features=6, out_features=15, bias=True)
  )
  (_and_l): XLinear(
    (_l): Linear(in_features=15, out_features=16, bias=False)
  )
  (_or_l): XLinear(
    (_l): Linear(in_features=16, out_features=3, bias=False)
  )
)
13-08-23 04:22[root]INFO | Value Net Arch: Sequential(
  (0): Linear(in_features=6, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=32, bias=True)
  (3): ReLU()
  (4): Linear(in_features=32, out_features=1, bias=True)
)
13-08-23 04:22[root]INFO | ==============> Test reward for seeds [500, 600]: -80.77 +/- 16.324738895308556 <==========
13-08-23 04:22[root]INFO | Execution time of seed 110: 0 hours, 16 minutes, 13 seconds
