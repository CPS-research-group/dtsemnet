20-04-24 15:22[root]INFO | Training on env: walker
20-04-24 15:22[root]INFO | Agent Type: dgt
20-04-24 15:22[root]INFO | Log Directory: ./logs/walker_cpu/dgt/32leaves_33-22-15-20-Apr_Final/
20-04-24 15:22[root]INFO | GPU?: False
20-04-24 15:22[root]INFO | Num Leaves: 32
20-04-24 15:22[root]INFO | DGT Policy
20-04-24 15:22[root]INFO | Value Net Size: [256, 256]
20-04-24 15:22[root]INFO | [START]======> Training Started for Seed [17]: 2024-04-20 15:22:39
20-04-24 15:22[root]INFO | actor: DGTActor(
  (features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (drnet): DGT(
    (_and_act_fn): Softmax(dim=-1)
    (_predicate_l): Sequential(
      (0): Linear(in_features=24, out_features=31, bias=True)
    )
    (_and_l): XLinear(
      (_l): Linear(in_features=31, out_features=32, bias=False)
    )
    (_or_l): XLinear(
      (_l): Linear(in_features=32, out_features=4, bias=False)
    )
  )
)
20-04-24 15:22[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 0, Avg Reward: -99.49971721507609, Best: -99.49971721507609
20-04-24 15:22[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=1500, Reward=-23.80 +/- 6.25, EpLength: 1600.00 +/- 0.00
20-04-24 15:22[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:22[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=3000, Reward=-23.76 +/- 7.82, EpLength: 1600.00 +/- 0.00
20-04-24 15:22[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=4500, Reward=-29.68 +/- 2.17, EpLength: 1600.00 +/- 0.00
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 10, Avg Reward: -97.47239210367553, Best: -92.63044177020515
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=6000, Reward=-47.99 +/- 41.26, EpLength: 1321.60 +/- 556.80
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=7500, Reward=-23.52 +/- 7.35, EpLength: 1600.00 +/- 0.00
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=9000, Reward=-68.31 +/- 50.83, EpLength: 1040.60 +/- 685.18
20-04-24 15:24[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=10500, Reward=-112.43 +/- 0.25, EpLength: 151.60 +/- 3.88
20-04-24 15:24[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 20, Avg Reward: -106.64218333250517, Best: -92.63044177020515
20-04-24 15:25[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=12000, Reward=-120.99 +/- 0.04, EpLength: 43.00 +/- 0.00
20-04-24 15:25[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 30, Avg Reward: -113.38433751527968, Best: -92.63044177020515
20-04-24 15:25[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 40, Avg Reward: -115.63218397337828, Best: -92.63044177020515
20-04-24 15:26[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 50, Avg Reward: -117.46719226182364, Best: -92.63044177020515
20-04-24 15:26[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=13500, Reward=-121.03 +/- 0.01, EpLength: 43.00 +/- 0.00
20-04-24 15:27[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=15000, Reward=-97.55 +/- 1.04, EpLength: 90.80 +/- 2.40
20-04-24 15:28[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=16500, Reward=-125.78 +/- 0.46, EpLength: 100.40 +/- 2.06
20-04-24 15:29[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 60, Avg Reward: -118.26351680854096, Best: -92.63044177020515
20-04-24 15:29[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=18000, Reward=-125.64 +/- 0.33, EpLength: 100.20 +/- 1.60
20-04-24 15:30[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 70, Avg Reward: -119.36367743903196, Best: -92.63044177020515
20-04-24 15:30[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=19500, Reward=-125.77 +/- 0.46, EpLength: 100.00 +/- 1.41
20-04-24 15:31[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 80, Avg Reward: -119.65444339707288, Best: -92.63044177020515
20-04-24 15:31[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 90, Avg Reward: -119.16108077792543, Best: -92.63044177020515
20-04-24 15:31[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=21000, Reward=-101.64 +/- 0.07, EpLength: 69.20 +/- 0.40
20-04-24 15:32[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 100, Avg Reward: -119.84640464655641, Best: -92.63044177020515
20-04-24 15:32[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=22500, Reward=-101.59 +/- 0.07, EpLength: 68.80 +/- 0.40
20-04-24 15:33[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 110, Avg Reward: -120.7972267421365, Best: -92.63044177020515
20-04-24 15:34[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 120, Avg Reward: -119.93098687121562, Best: -92.63044177020515
20-04-24 15:34[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=24000, Reward=-101.56 +/- 0.09, EpLength: 68.60 +/- 0.49
20-04-24 15:34[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 130, Avg Reward: -118.17676757123414, Best: -92.63044177020515
20-04-24 15:34[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=25500, Reward=-101.60 +/- 0.07, EpLength: 68.80 +/- 0.40
20-04-24 15:35[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 140, Avg Reward: -117.14518856146495, Best: -92.63044177020515
20-04-24 15:36[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=27000, Reward=-95.66 +/- 0.02, EpLength: 83.40 +/- 0.49
