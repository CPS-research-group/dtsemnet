20-04-24 15:23[root]INFO | Training on env: walker
20-04-24 15:23[root]INFO | Agent Type: dgt
20-04-24 15:23[root]INFO | Log Directory: ./logs/walker_cpu/dgt/128leaves_17-23-15-20-Apr_Final/
20-04-24 15:23[root]INFO | GPU?: False
20-04-24 15:23[root]INFO | Num Leaves: 128
20-04-24 15:23[root]INFO | DGT Policy
20-04-24 15:23[root]INFO | Value Net Size: [256, 256]
20-04-24 15:23[root]INFO | [START]======> Training Started for Seed [13]: 2024-04-20 15:23:24
20-04-24 15:23[root]INFO | actor: DGTActor(
  (features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (drnet): DGT(
    (_and_act_fn): Softmax(dim=-1)
    (_predicate_l): Sequential(
      (0): Linear(in_features=24, out_features=127, bias=True)
    )
    (_and_l): XLinear(
      (_l): Linear(in_features=127, out_features=128, bias=False)
    )
    (_or_l): XLinear(
      (_l): Linear(in_features=128, out_features=4, bias=False)
    )
  )
)
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 0, Avg Reward: -101.484948448473, Best: -101.484948448473
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=1500, Reward=-107.65 +/- 5.70, EpLength: 134.80 +/- 14.37
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=3000, Reward=-107.53 +/- 5.89, EpLength: 149.20 +/- 9.74
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=4500, Reward=-110.07 +/- 4.83, EpLength: 158.20 +/- 14.39
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=6000, Reward=-105.17 +/- 5.80, EpLength: 142.20 +/- 12.81
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 10, Avg Reward: -98.42840234429985, Best: -91.05536908403701
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=7500, Reward=-107.59 +/- 5.94, EpLength: 151.60 +/- 12.42
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=9000, Reward=-100.36 +/- 0.09, EpLength: 132.80 +/- 9.74
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 20, Avg Reward: -100.71589667847145, Best: -91.05536908403701
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 30, Avg Reward: -104.4442769787487, Best: -91.05536908403701
20-04-24 15:24[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=10500, Reward=-68.60 +/- 0.10, EpLength: 1600.00 +/- 0.00
20-04-24 15:24[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:25[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=12000, Reward=-118.32 +/- 30.43, EpLength: 1600.00 +/- 0.00
20-04-24 15:27[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=13500, Reward=-101.03 +/- 30.42, EpLength: 1600.00 +/- 0.00
20-04-24 15:28[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=15000, Reward=-99.07 +/- 21.76, EpLength: 1600.00 +/- 0.00
20-04-24 15:30[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=16500, Reward=-111.64 +/- 0.46, EpLength: 123.20 +/- 5.00
20-04-24 15:30[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=18000, Reward=-111.40 +/- 0.12, EpLength: 120.00 +/- 1.41
20-04-24 15:31[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=19500, Reward=-111.71 +/- 0.34, EpLength: 123.80 +/- 4.26
20-04-24 15:31[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 40, Avg Reward: -116.11378299127234, Best: -91.05536908403701
20-04-24 15:32[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=21000, Reward=-122.49 +/- 20.56, EpLength: 424.20 +/- 587.92
20-04-24 15:32[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=22500, Reward=-119.54 +/- 0.88, EpLength: 73.40 +/- 0.80
20-04-24 15:33[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 50, Avg Reward: -119.15759068643759, Best: -91.05536908403701
20-04-24 15:33[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=24000, Reward=-120.44 +/- 0.97, EpLength: 74.20 +/- 0.98
20-04-24 15:33[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 60, Avg Reward: -119.92576608136122, Best: -91.05536908403701
20-04-24 15:34[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=25500, Reward=-120.07 +/- 0.97, EpLength: 73.80 +/- 0.98
20-04-24 15:34[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 70, Avg Reward: -121.16130517816134, Best: -91.05536908403701
20-04-24 15:34[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=27000, Reward=-120.06 +/- 0.96, EpLength: 73.80 +/- 0.98
20-04-24 15:35[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=28500, Reward=-119.68 +/- 0.78, EpLength: 73.40 +/- 0.80
20-04-24 15:35[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 80, Avg Reward: -123.07467109186503, Best: -91.05536908403701
20-04-24 15:36[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=30000, Reward=-120.08 +/- 0.97, EpLength: 73.80 +/- 0.98
20-04-24 15:36[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 90, Avg Reward: -123.94746928273716, Best: -91.05536908403701
20-04-24 15:36[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=31500, Reward=-119.26 +/- 1.01, EpLength: 73.40 +/- 0.80
20-04-24 15:37[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=33000, Reward=-105.73 +/- 0.19, EpLength: 116.80 +/- 2.64
