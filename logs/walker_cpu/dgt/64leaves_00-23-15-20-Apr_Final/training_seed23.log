20-04-24 15:23[root]INFO | Training on env: walker
20-04-24 15:23[root]INFO | Agent Type: dgt
20-04-24 15:23[root]INFO | Log Directory: ./logs/walker_cpu/dgt/64leaves_00-23-15-20-Apr_Final/
20-04-24 15:23[root]INFO | GPU?: False
20-04-24 15:23[root]INFO | Num Leaves: 64
20-04-24 15:23[root]INFO | DGT Policy
20-04-24 15:23[root]INFO | Value Net Size: [256, 256]
20-04-24 15:23[root]INFO | [START]======> Training Started for Seed [23]: 2024-04-20 15:23:07
20-04-24 15:23[root]INFO | actor: DGTActor(
  (features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (drnet): DGT(
    (_and_act_fn): Softmax(dim=-1)
    (_predicate_l): Sequential(
      (0): Linear(in_features=24, out_features=63, bias=True)
    )
    (_and_l): XLinear(
      (_l): Linear(in_features=63, out_features=64, bias=False)
    )
    (_or_l): XLinear(
      (_l): Linear(in_features=64, out_features=4, bias=False)
    )
  )
)
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=1500, Reward=-100.71 +/- 0.08, EpLength: 80.80 +/- 1.33
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 0, Avg Reward: -83.35245116192823, Best: -83.35245116192823
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=3000, Reward=-100.59 +/- 0.11, EpLength: 80.80 +/- 0.98
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=4500, Reward=-100.58 +/- 0.25, EpLength: 80.40 +/- 0.80
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=6000, Reward=-100.63 +/- 0.12, EpLength: 80.20 +/- 0.98
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 10, Avg Reward: -102.01928043491925, Best: -83.35245116192823
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=7500, Reward=-100.47 +/- 0.21, EpLength: 80.60 +/- 0.80
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=9000, Reward=-100.56 +/- 0.25, EpLength: 81.20 +/- 0.98
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 20, Avg Reward: -103.73881640629514, Best: -83.35245116192823
20-04-24 15:23[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=10500, Reward=-103.41 +/- 2.06, EpLength: 56.00 +/- 10.00
20-04-24 15:24[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 30, Avg Reward: -109.83738487924361, Best: -83.35245116192823
20-04-24 15:24[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 40, Avg Reward: -111.13182493628051, Best: -83.35245116192823
20-04-24 15:24[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=12000, Reward=-112.51 +/- 0.69, EpLength: 126.60 +/- 26.36
20-04-24 15:25[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 50, Avg Reward: -112.35322853453647, Best: -83.35245116192823
20-04-24 15:25[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=13500, Reward=-116.37 +/- 0.83, EpLength: 100.20 +/- 6.18
20-04-24 15:26[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 60, Avg Reward: -112.85168392630773, Best: -83.35245116192823
20-04-24 15:26[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 70, Avg Reward: -113.57257861184108, Best: -83.35245116192823
20-04-24 15:27[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=15000, Reward=-119.85 +/- 2.39, EpLength: 142.20 +/- 70.90
20-04-24 15:27[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 80, Avg Reward: -114.40035209641962, Best: -83.35245116192823
20-04-24 15:28[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=16500, Reward=-92.47 +/- 0.04, EpLength: 120.20 +/- 2.56
20-04-24 15:28[icct.rl_helpers.eval_callback]INFO | (Save ) Storing Best Model: New best mean reward!
20-04-24 15:28[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 90, Avg Reward: -114.78519832332493, Best: -83.35245116192823
20-04-24 15:29[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=18000, Reward=-113.89 +/- 0.34, EpLength: 93.20 +/- 1.17
20-04-24 15:31[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=19500, Reward=-171.96 +/- 0.02, EpLength: 1600.00 +/- 0.00
20-04-24 15:31[icct.rl_helpers.eval_callback]INFO | (Train) Episode: 100, Avg Reward: -115.68782193956523, Best: -83.35245116192823
20-04-24 15:32[icct.rl_helpers.eval_callback]INFO | (Eval ) num_timesteps=21000, Reward=-98.11 +/- 0.82, EpLength: 117.60 +/- 6.56
