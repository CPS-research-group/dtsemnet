07-11-24 04:33[root]INFO | Training on cart environment for 1500 episodes
07-11-24 04:33[root]INFO | Agent Type: dtnet
07-11-24 04:33[root]INFO | Log Directory: cart_cpu/dtnet/aaai_v2_new_rand/
07-11-24 04:33[root]INFO | Random Weight Initialization: True
07-11-24 04:33[root]INFO | Training Started: 2024-11-07 04:33:24
07-11-24 04:33[root]INFO | Using Cart Pole Environment
07-11-24 04:33[root]INFO | Hyperparameters: {"learning_rate": 0.024, "gamma": 0.99, "batch_size": 32, "n_steps": 832, "ent_coef": 0.02, "clip_range": 0.2, "vf_coef": 0.5, "max_grad_norm": 0.5, "gae_lambda": 0.86, "n_epochs": 20}
07-11-24 04:33[root]INFO | ===================> Training with seed 112 <=================
07-11-24 04:33[root]INFO | Using DTNet agent
07-11-24 04:33[root]INFO | Using cartpole architecture 16x16
07-11-24 04:33[root]INFO | Action Net Arch: DTNetv0(
  (linear1): Linear(in_features=4, out_features=15, bias=True)
  (reluP): ReLU()
  (reluM): ReLU()
  (linear2): Linear(in_features=30, out_features=16, bias=False)
  (mpool): MaxPoolLayer()
  (softmax): Softmax(dim=-1)
)
07-11-24 04:33[root]INFO | Value Net Arch: FCNN(
  (layer1): Linear(in_features=4, out_features=16, bias=True)
  (layer2): Linear(in_features=16, out_features=16, bias=True)
  (activation): ReLU()
  (layer3): Linear(in_features=16, out_features=2, bias=True)
  (value_output): Linear(in_features=2, out_features=1, bias=True)
)
07-11-24 04:33[root]INFO | Episode: 0, Avg Reward: 12.0, Best Eval: -inf
07-11-24 04:33[root]INFO | Episode: 50, Avg Reward: 19.901960784313726, Best Eval: -inf
07-11-24 04:34[root]INFO | Episode: 100, Avg Reward: 32.75, Best Eval: -inf
07-11-24 04:37[root]INFO | Episode: 150, Avg Reward: 162.12, Best Eval: -inf
07-11-24 04:44[root]INFO | Episode: 200, Avg Reward: 387.89, Best Eval: -inf
07-11-24 04:50[root]INFO | Episode: 250, Avg Reward: 460.12, Best Eval: 500.0
07-11-24 04:53[root]INFO | Episode: 300, Avg Reward: 337.13, Best Eval: 500.0
07-11-24 04:58[root]INFO | Episode: 350, Avg Reward: 325.8, Best Eval: 500.0
07-11-24 05:02[root]INFO | Episode: 400, Avg Reward: 371.29, Best Eval: 500.0
07-11-24 05:07[root]INFO | Episode: 450, Avg Reward: 323.89, Best Eval: 500.0
07-11-24 05:12[root]INFO | Episode: 500, Avg Reward: 342.28, Best Eval: 500.0
07-11-24 05:18[root]INFO | Episode: 550, Avg Reward: 431.09, Best Eval: 500.0
07-11-24 05:24[root]INFO | Episode: 600, Avg Reward: 471.45, Best Eval: 500.0
07-11-24 05:30[root]INFO | Episode: 650, Avg Reward: 457.91, Best Eval: 500.0
07-11-24 05:33[root]INFO | Episode: 700, Avg Reward: 345.48, Best Eval: 500.0
07-11-24 05:35[root]INFO | Episode: 750, Avg Reward: 179.13, Best Eval: 500.0
07-11-24 05:40[root]INFO | Episode: 800, Avg Reward: 247.08, Best Eval: 500.0
07-11-24 05:47[root]INFO | Episode: 850, Avg Reward: 416.37, Best Eval: 500.0
07-11-24 05:53[root]INFO | Episode: 900, Avg Reward: 473.75, Best Eval: 500.0
07-11-24 05:58[root]INFO | Episode: 950, Avg Reward: 424.69, Best Eval: 500.0
07-11-24 06:04[root]INFO | Episode: 1000, Avg Reward: 398.95, Best Eval: 500.0
07-11-24 06:08[root]INFO | Episode: 1050, Avg Reward: 382.43, Best Eval: 500.0
07-11-24 06:13[root]INFO | Episode: 1100, Avg Reward: 350.57, Best Eval: 500.0
07-11-24 06:17[root]INFO | Episode: 1150, Avg Reward: 341.49, Best Eval: 500.0
07-11-24 06:23[root]INFO | Episode: 1200, Avg Reward: 374.18, Best Eval: 500.0
07-11-24 06:29[root]INFO | Episode: 1250, Avg Reward: 430.48, Best Eval: 500.0
07-11-24 06:34[root]INFO | Episode: 1300, Avg Reward: 448.54, Best Eval: 500.0
07-11-24 06:38[root]INFO | Episode: 1350, Avg Reward: 438.99, Best Eval: 500.0
07-11-24 06:42[root]INFO | Episode: 1400, Avg Reward: 439.22, Best Eval: 500.0
07-11-24 06:43[root]INFO | Episode: 1450, Avg Reward: 401.35, Best Eval: 500.0
07-11-24 06:44[root]INFO | Using DTNet agent
07-11-24 06:44[root]INFO | Using cartpole architecture 16x16
07-11-24 06:44[root]INFO | Action Net Arch: DTNetv0(
  (linear1): Linear(in_features=4, out_features=15, bias=True)
  (reluP): ReLU()
  (reluM): ReLU()
  (linear2): Linear(in_features=30, out_features=16, bias=False)
  (mpool): MaxPoolLayer()
  (softmax): Softmax(dim=-1)
)
07-11-24 06:44[root]INFO | Value Net Arch: FCNN(
  (layer1): Linear(in_features=4, out_features=16, bias=True)
  (layer2): Linear(in_features=16, out_features=16, bias=True)
  (activation): ReLU()
  (layer3): Linear(in_features=16, out_features=2, bias=True)
  (value_output): Linear(in_features=2, out_features=1, bias=True)
)
07-11-24 06:45[root]INFO | ==============> Test reward for seeds [500, 600]: 500.00 +/- 0.0 <==========
07-11-24 06:45[root]INFO | Execution time of seed 112: 2 hours, 11 minutes, 49 seconds
