07-11-24 04:33[root]INFO | Training on cart environment for 1500 episodes
07-11-24 04:33[root]INFO | Agent Type: dtnet
07-11-24 04:33[root]INFO | Log Directory: cart_cpu/dtnet/aaai_v2_new_rand/
07-11-24 04:33[root]INFO | Random Weight Initialization: True
07-11-24 04:33[root]INFO | Training Started: 2024-11-07 04:33:15
07-11-24 04:33[root]INFO | Using Cart Pole Environment
07-11-24 04:33[root]INFO | Hyperparameters: {"learning_rate": 0.024, "gamma": 0.99, "batch_size": 32, "n_steps": 832, "ent_coef": 0.02, "clip_range": 0.2, "vf_coef": 0.5, "max_grad_norm": 0.5, "gae_lambda": 0.86, "n_epochs": 20}
07-11-24 04:33[root]INFO | ===================> Training with seed 100 <=================
07-11-24 04:33[root]INFO | Using DTNet agent
07-11-24 04:33[root]INFO | Using cartpole architecture 16x16
07-11-24 04:33[root]INFO | Action Net Arch: DTNetv0(
  (linear1): Linear(in_features=4, out_features=15, bias=True)
  (reluP): ReLU()
  (reluM): ReLU()
  (linear2): Linear(in_features=30, out_features=16, bias=False)
  (mpool): MaxPoolLayer()
  (softmax): Softmax(dim=-1)
)
07-11-24 04:33[root]INFO | Value Net Arch: FCNN(
  (layer1): Linear(in_features=4, out_features=16, bias=True)
  (layer2): Linear(in_features=16, out_features=16, bias=True)
  (activation): ReLU()
  (layer3): Linear(in_features=16, out_features=2, bias=True)
  (value_output): Linear(in_features=2, out_features=1, bias=True)
)
07-11-24 04:33[root]INFO | Episode: 0, Avg Reward: 16.0, Best Eval: -inf
07-11-24 04:33[root]INFO | Episode: 50, Avg Reward: 24.529411764705884, Best Eval: -inf
07-11-24 04:34[root]INFO | Episode: 100, Avg Reward: 47.79, Best Eval: -inf
07-11-24 04:36[root]INFO | Episode: 150, Avg Reward: 140.54, Best Eval: -inf
07-11-24 04:40[root]INFO | Episode: 200, Avg Reward: 256.33, Best Eval: -inf
07-11-24 04:43[root]INFO | Episode: 250, Avg Reward: 251.68, Best Eval: 462.06666666666666
07-11-24 04:47[root]INFO | Episode: 300, Avg Reward: 248.13, Best Eval: 500.0
07-11-24 04:52[root]INFO | Episode: 350, Avg Reward: 312.26, Best Eval: 500.0
07-11-24 04:57[root]INFO | Episode: 400, Avg Reward: 349.18, Best Eval: 500.0
07-11-24 05:03[root]INFO | Episode: 450, Avg Reward: 417.34, Best Eval: 500.0
07-11-24 05:09[root]INFO | Episode: 500, Avg Reward: 482.74, Best Eval: 500.0
07-11-24 05:14[root]INFO | Episode: 550, Avg Reward: 429.02, Best Eval: 500.0
07-11-24 05:19[root]INFO | Episode: 600, Avg Reward: 363.61, Best Eval: 500.0
07-11-24 05:24[root]INFO | Episode: 650, Avg Reward: 351.93, Best Eval: 500.0
07-11-24 05:30[root]INFO | Episode: 700, Avg Reward: 407.82, Best Eval: 500.0
07-11-24 05:37[root]INFO | Episode: 750, Avg Reward: 482.93, Best Eval: 500.0
07-11-24 05:42[root]INFO | Episode: 800, Avg Reward: 464.8, Best Eval: 500.0
07-11-24 05:48[root]INFO | Episode: 850, Avg Reward: 418.4, Best Eval: 500.0
07-11-24 05:53[root]INFO | Episode: 900, Avg Reward: 392.74, Best Eval: 500.0
07-11-24 05:58[root]INFO | Episode: 950, Avg Reward: 371.49, Best Eval: 500.0
07-11-24 06:02[root]INFO | Episode: 1000, Avg Reward: 328.88, Best Eval: 500.0
07-11-24 06:08[root]INFO | Episode: 1050, Avg Reward: 379.39, Best Eval: 500.0
07-11-24 06:13[root]INFO | Episode: 1100, Avg Reward: 442.82, Best Eval: 500.0
07-11-24 06:18[root]INFO | Episode: 1150, Avg Reward: 400.67, Best Eval: 500.0
07-11-24 06:22[root]INFO | Episode: 1200, Avg Reward: 310.24, Best Eval: 500.0
07-11-24 06:24[root]INFO | Episode: 1250, Avg Reward: 222.93, Best Eval: 500.0
07-11-24 06:29[root]INFO | Episode: 1300, Avg Reward: 263.51, Best Eval: 500.0
07-11-24 06:35[root]INFO | Episode: 1350, Avg Reward: 403.65, Best Eval: 500.0
07-11-24 06:38[root]INFO | Episode: 1400, Avg Reward: 455.11, Best Eval: 500.0
07-11-24 06:41[root]INFO | Episode: 1450, Avg Reward: 411.38, Best Eval: 500.0
07-11-24 06:43[root]INFO | Using DTNet agent
07-11-24 06:43[root]INFO | Using cartpole architecture 16x16
07-11-24 06:43[root]INFO | Action Net Arch: DTNetv0(
  (linear1): Linear(in_features=4, out_features=15, bias=True)
  (reluP): ReLU()
  (reluM): ReLU()
  (linear2): Linear(in_features=30, out_features=16, bias=False)
  (mpool): MaxPoolLayer()
  (softmax): Softmax(dim=-1)
)
07-11-24 06:43[root]INFO | Value Net Arch: FCNN(
  (layer1): Linear(in_features=4, out_features=16, bias=True)
  (layer2): Linear(in_features=16, out_features=16, bias=True)
  (activation): ReLU()
  (layer3): Linear(in_features=16, out_features=2, bias=True)
  (value_output): Linear(in_features=2, out_features=1, bias=True)
)
07-11-24 06:44[root]INFO | ==============> Test reward for seeds [500, 600]: 500.00 +/- 0.0 <==========
07-11-24 06:44[root]INFO | Execution time of seed 100: 2 hours, 11 minutes, 3 seconds
